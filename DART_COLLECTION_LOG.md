# DART 제조업 상장사 데이터 수집 프로젝트 (Dart_data_collect)

## 0. Current Policy (2026-02-26)
- `industry_classification` in each `raw_*.json` stores only one field: `"소분류"`.
- `"소분류"` value is sourced directly from column D (`업종`) of `상장법인목록.xls`.
- `data/stock_master_list.csv` is deprecated and no longer used by collection logic.
- `collect_dart_manufacturing.py` now reads `상장법인목록.xls` directly as the single source of industry label input.

본 문서는 V-Search 프로젝트에서 파생된 "DART 원시 데이터 수집 파이프라인"의 구축 배경, 목적, 방법론, 그리고 개발 과정에서 마주한 애로사항 및 해결 과정을 상세히 기록합니다. 이 폴더(`Dart_data_collect`)는 독립적인 깃허브 Repository 업로드용으로 분리되었습니다.

## 1. 프로젝트 목적
* **자유로운 다각도 분석**: 기존 파이프라인은 DART 데이터를 수집하자마자 LLM(Gemini)을 통해 바로 요약/평가하는 구조였습니다. 본 수집 프로젝트는 LLM 단계를 배제하고, 향후 어떠한 언어 모델이나 분석 기법(AI 알고리즘, 통계형 분석 등)에도 유연하게 적용할 수 있도록 **"DART 원본 텍스트(사업의 내용 파트 전체)"와 "핵심 재무제표 원시 데이터"를 있는 그대로 보존하여 적재**하는 데 목적이 있습니다.

## 2. 수집 대상 및 방법론
* **수집 대상**: 
  * '코스피(유가증권)' 및 '코스닥' 상장 법인 중, 상장일이 **2023년 1월 1일 이전**인 기업 (2024년 사업보고서 공시가 확실한 기업들).
  * 한국표준산업분류 통계청 기준 **[대분류 C: 제조업 (분류코드 10~34)]**에 직간접적으로 속하는 기업군.
* **사용 기술**: `Python`, `OpenDartReader` (DART Open API 래퍼), `pandas` (엑셀 파싱 및 필터링), `BeautifulSoup` (HTML 파싱).
* **결과물**: 각 기업별 종목코드를 파일명으로 하는 JSON (예: `data/raw_005930.json`)
  * `business_description`: 'II. 사업의 내용' 파트의 모든 텍스트 원문 (HTML 태그가 정제된 평문)
  * `financials`: 당기순이익, 자본, 부채 등 개별 계정과목 및 금액 Dictionary

## 3. 개발 과정 중 애로사항 및 해결 방법 (Troubleshooting)

### 이슈 1: 무자비한 API 호출로 인한 Rate Limit 및 속도 저하 문제
- **상황**: DART의 '기업개황 API'를 활용해 전수 조사를 하며 제조업 여부(`induty_cd` 검증)를 체크하려 했으나, 호출 횟수 제한(10,000회/일 등) 및 심각한 속도 지연이 우려되었습니다.
- **해결**: 사용자 측에서 최신화하여 제공한 `상장법인목록.xls` 파일과 `업종코드 연계표.xlsx`를 로컬에서 직접 파싱하는 방식으로 전면 수정. pandas로 로컬 파일들을 즉시 메모리에 올려 필터링함으로써, 네트워크 통신 비용과 API 호출량을 **제로(0) 수준으로 단축**했습니다.

### 이슈 2: 다운로드한 엑셀 파일의 심각한 인코딩 및 위장 확장자 문제
- **상황**: `상장법인목록.xls`가 실제 `.xls` 규격이 아니라 `xml/html` 형식의 웹 테이블이었으며, 내부 한글 인코딩이 EUC-KR(또는 CP949)로 되어 있어 `pd.read_excel()` 진행 시 BOF Error 및 깨짐 현상이 발생했습니다.
- **해결**: `xlrd`나 `openpyxl` 등 범용 엑셀 엔진을 폐기하고, 곧바로 `pd.read_html(..., encoding='cp949')`를 적용해 테이블을 파싱하여 완벽하게 데이터프레임을 복구했습니다.

### 이슈 3: 신규 상장사들의 데이터 누락 (공시 부재)
- **상황**: 초기 샘플링한 10개 기업(스팩, 25~26년 신생 상장사 등)에 대해 DART API 호출 시, 사업보고서 및 재무 데이터 전체가 텅 비어서 반환되는 문제 발생.
- **해결**: 이들은 2024년 결산 사업보고서가 원천적으로 존재하지 않는다는 사실을 규명. 이를 시스템 로직으로 원천 차단하기 위해 엑셀 파싱 단계에서 `상장일 < '2023-01-01'` 인 기업만 남기도록 데이터프레임 필터링(Time Series Filter)을 추가 도입하여 공백 에러를 완벽히 막았습니다.

### 이슈 4: '사업의 내용' 본문 텍스트 도중 잘림/누락 (가장 심각했던 문제)
- **상황**: 삼미금속(012210) 등 여러 기업 검증 결과, "II. 사업의 내용" 텍스트가 9,000자 내외의 목차 초중반부("조직도" 부근)에서 뚝 끊기는 치명적인 누락이 발견되었습니다. 정교하게 파트(매출, 판매경로 등)를 쪼개지 않고 전체를 통으로 가져왔음에도 데이터가 손실되었습니다.
- **해결**: DART의 문서 공시 시스템 특성을 분석한 결과, 일부 기업들은 "II. 사업의 내용" 산하의 수많은 목차(`1. 사업의 개요`, `2. 주요제품 및 서비스` 등)를 하나의 문서(`document`)가 아니라 **수십 개의 잘게 쪼개진 하위 URL(Sub-docs)**들로 분리 결합하여 공시한다는 점을 파악했습니다.
- 따라서 `OpenDartReader.sub_docs()`를 이용해 하위 문서 트리를 탐색한 후, **"II. 사업의 내용"이 나타난 순간부터 그 다음 대목차(일반적으로 "III. 재무" 등)가 등장하기 전까지의 모든 하위 URL들을 순회 탐색(Iterate)하며 HTTP GET으로 텍스트를 연달아 이어붙이는(Concat)** 병합 알고리즘으로 스크립트를 전면 교체했습니다. 결과적으로 기존 9천여 자에서 누락되었던 후반부 1만 자 이상이 정상 복구되어 100% 완벽한 텍스트 덤프가 가능해졌습니다.

## 4. 실행 지침 (How to Use)
해당 폴더 내부에서 다음 명령어를 실행하면 사전에 세팅된 `data` 디렉토리 내에 파싱된 기업별 json 데이터가 쌓입니다.
```bash
python collect_dart_manufacturing.py
```
*(참고: `fetch_dart_data()` 함수 내의 `limit = 10` 부분을 해제해야 전체 기업이 조달됩니다.)*
